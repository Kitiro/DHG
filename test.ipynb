{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.resnet import make_resnet101_base, make_resnet50_base\n",
    "from utils import set_gpu, pick_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vietnamese-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: 2-hops, 1549 classes, ratio=0.1\n",
      "consider train classifiers: True\n"
     ]
    }
   ],
   "source": [
    "test_set = '2-hops'\n",
    "test_sets = json.load(open('materials/imagenet-testsets.json', 'r'))\n",
    "train_wnids = test_sets['train']\n",
    "test_wnids = test_sets[test_set]\n",
    "\n",
    "keep_ratio = 0.1\n",
    "consider_trains = True\n",
    "print('test set: {}, {} classes, ratio={}'\n",
    "      .format(test_set, len(test_wnids), keep_ratio))\n",
    "print('consider train classifiers: {}'.format(consider_trains))\n",
    "\n",
    "# pred = 'save/gcn-att/best_val.pred'\n",
    "# pred = 'save/gcn-dense-aux/best_val.pred'\n",
    "# pred_file = torch.load(pred)\n",
    "# pred_wnids = pred_file['wnids']\n",
    "# pred_vectors = pred_file['pred']\n",
    "# pred_dic = dict(zip(pred_wnids, pred_vectors))\n",
    "# pred_vectors = pick_vectors(pred_dic, train_wnids + test_wnids, is_tensor=True).cuda()  # 得到train和test的预测的分类器\n",
    "\n",
    "# pred_vectors = pred_vectors.cuda()\n",
    "\n",
    "n = len(train_wnids)\n",
    "m = len(test_wnids)\n",
    "\n",
    "# cnn = eval(f'make_resnet101_base()')\n",
    "# cnn.load_state_dict(torch.load(f'materials/resnet101-base.pth'))\n",
    "# cnn = cnn.cuda()\n",
    "# cnn.eval()\n",
    "\n",
    "TEST_TRAIN = True\n",
    "\n",
    "s_hits = torch.FloatTensor([0, 0, 0, 0, 0]).cuda() # top 1 2 5 10 20\n",
    "s_tot = 0\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spectacular-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过预提取保存到本地的image feature进行test\n",
    "npy_path = '/home/zzc/datasets/imagenet_feats'\n",
    "def test_on_subset_local(wnid, n, pred_vectors, all_label,\n",
    "                   consider_trains):\n",
    "    top = [1, 2, 5, 10, 20]\n",
    "    hits = torch.zeros(len(top)).cuda()\n",
    "    tot = 0\n",
    "    \n",
    "    feat = torch.FloatTensor(np.load(os.path.join(npy_path, f'{wnid}.npy'))).cuda()\n",
    "    feat = torch.cat([feat, torch.ones(len(feat)).view(-1, 1).cuda()], dim=1)\n",
    "    fcs = pred_vectors.t()\n",
    "\n",
    "    table = torch.matmul(feat, fcs)\n",
    "    if not consider_trains:\n",
    "        table[:, :n] = -1e18  # 将train class部分置0\n",
    "\n",
    "    gth_score = table[:, all_label].repeat(table.shape[1], 1).t() # 该batch内，target label的score\n",
    "    rks = (table >= gth_score).sum(dim=1)  # 若其他类预测分数大于target类，则说明分类错误；若rk==1，则说明分类正确。\n",
    "\n",
    "    assert (table[:, all_label] == gth_score[:, all_label]).min() == 1\n",
    "\n",
    "    for i, k in enumerate(top):\n",
    "        hits[i] += (rks <= k).sum().item()\n",
    "    tot += len(feat)\n",
    "\n",
    "    return hits, tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "administrative-rebound",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary: 21.50% 34.60% 52.80% 64.35% 73.28% "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_set = '2-hops'\n",
    "test_wnids = test_sets[test_set]\n",
    "\n",
    "save = 'gcn-att-r-4layers' # gcn-att\n",
    "pred = f'{save}/best_val.pred'\n",
    "pred_file = torch.load(pred)\n",
    "pred_wnids = pred_file['wnids']\n",
    "pred_vectors = pred_file['pred']\n",
    "pred_dic = dict(zip(pred_wnids, pred_vectors))\n",
    "pred_vectors = pick_vectors(pred_dic, train_wnids + test_wnids, is_tensor=True).cuda()  # 得到train和test的预测的分类器\n",
    "\n",
    "s_hits = torch.FloatTensor([0, 0, 0, 0, 0]).cuda() # top 1 2 5 10 20\n",
    "s_tot = 0\n",
    "\n",
    "# for idx, wnid in enumerate(train_wnids, 1):\n",
    "#     if not os.path.exists(os.path.join(npy_path, f'{wnid}.npy')):\n",
    "#         continue    \n",
    "#     hits, tot = test_on_subset_local(wnid, n, pred_vectors, idx - 1,\n",
    "#                                consider_trains=True)\n",
    "\n",
    "#     s_hits += hits\n",
    "#     s_tot += tot\n",
    "\n",
    "# #     print('{}/{}, {}:'.format(idx, len(train_wnids), wnid), end=' ')\n",
    "# #     for i in range(len(hits)):\n",
    "# #         print('{:.0f}%({:.2f}%)'\n",
    "# #               .format(hits[i] / tot * 100, s_hits[i] / s_tot * 100), end=' ')\n",
    "#     print('x{}({})'.format(tot, s_tot))\n",
    "    \n",
    "for idx, wnid in enumerate(test_wnids, 1):\n",
    "    if not os.path.exists(os.path.join(npy_path, f'{wnid}.npy')):\n",
    "        continue    \n",
    "    hits, tot = test_on_subset_local(wnid, n, pred_vectors, n+idx-1,\n",
    "                               consider_trains=False)\n",
    "\n",
    "    s_hits += hits\n",
    "    s_tot += tot\n",
    "\n",
    "#     print('{}/{}, {}:'.format(idx, len(test_wnids), wnid), end=' ')\n",
    "#     for i in range(len(hits)):\n",
    "#         print('{:.0f}%({:.2f}%)'\n",
    "#               .format(hits[i] / tot * 100, s_hits[i] / s_tot * 100), end=' ')\n",
    "#     print('x{}({})'.format(tot, s_tot))\n",
    "\n",
    "print('summary:', end=' ')\n",
    "for s_hit in s_hits:\n",
    "    print('{:.2f}%'.format(s_hit / s_tot * 100), end=' ')\n",
    "# print('total {}'.format(s_tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "nell-edges-all-word1300:\n",
    "train: summary: 56.45% 76.70% 90.16% 94.69% 97.19% total 129022\n",
    "2-hops-zsl: 25.57% 39.26% 58.74% 70.91% 80.18% total 130590\n",
    "2-hops-gzsl:11.33% 25.92% 48.93% 63.25% 74.54% total 130590\n",
    "    \n",
    "gcn-att:\n",
    "2-hops:15.62% 25.53% 40.92% 53.42% 64.92% total 130590\n",
    "2-hops-gzsl:6.97% 14.76% 30.32% 43.12% 56.28% total 130590\n",
    "\n",
    "5, 20000:\n",
    "    18.87% 30.09% 45.99% 56.34% 65.16% \n",
    "    8.96% 19.07% 35.35% 47.07% 57.39% \n",
    "5,10000\n",
    "20.53% 32.21% 49.08% 60.86% 70.16%\n",
    "4,20000\n",
    "20.13% 31.92% 48.75% 60.18% 69.62%\n",
    "\n",
    "gcn-att-r: \n",
    "    padding 5, neighs 10000\n",
    "    2-hops: 18.60% 29.10% 43.93% 53.81% 61.55% total 130590\n",
    "    1.85% 12.09% 29.43% 41.14% 50.68% total 130590\n",
    "    padding 15, neighs 5000\n",
    "    14.86% 22.80% 36.30% 46.93% 57.20% total 130590\n",
    "    \n",
    "    10, 5000, 使用aux_attention \n",
    "    22.00% 33.74% 50.53% 61.93% 70.83%\n",
    "    9.49% 22.08% 40.90% 53.63% 64.32% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argsort(table, descending=True, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    m = np.mean(x, axis=0)\n",
    "    res = np.sum([np.sum([abs(a-b) for a, b in zip(xx, m)])/len(xx) for xx in x])/len(x)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from sklearn.preprocessing import scale \n",
    "path = '/home/zzc/exp/Hierarchically_Learning_The_Discriminative_Features_For_Zero_Shot_Learning/data'\n",
    "\n",
    "mat = sio.loadmat(os.path.join(path, f'AWA2_data','att_splits.mat'))\n",
    "att = mat['original_att'].T\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ['AWA2', 'CUB', 'APY', 'SUN']\n",
    "path = '/home/zzc/exp/Hierarchically_Learning_The_Discriminative_Features_For_Zero_Shot_Learning/data'\n",
    "for d in ds:\n",
    "    mat = sio.loadmat(os.path.join(path, f'{d}_data','att_splits.mat'))\n",
    "    att = mat['original_att'].T\n",
    "#     std = np.std(scale(att, axis=1), axis=0).mean()\n",
    "    print(d, f(att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat['original_att']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infor(data):\n",
    "    a = pd.value_counts(data) / len(data)\n",
    "    return sum(np.log2(a) * a * (-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
